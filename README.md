# LLM examples

This repository contains some examples of LLM deployments in Aalto University premises.

## Use local models

### Huggingface transformers

See [this document](./huggingface-models).

### Server via vLLM

See [this document](./server-via-vllm).

### Batch inference via vLLM

See [this document](./batch-inference-via-vllm).

### Chat with your pdf via langchain (RAG)

See [this document](./chat-with-pdf).

## Use Aalto's open-source LLM API

See [this document](./aalto-llm-api).
